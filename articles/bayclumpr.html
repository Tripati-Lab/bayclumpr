<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>bayclumpr • bayclumpr</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="bayclumpr">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">bayclumpr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item"><a class="nav-link" href="../articles/bayclumpr.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/Tripati-Lab/bayclumpr/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>bayclumpr</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/Tripati-Lab/bayclumpr/blob/master/vignettes/bayclumpr.Rmd" class="external-link"><code>vignettes/bayclumpr.Rmd</code></a></small>
      <div class="d-none name"><code>bayclumpr.Rmd</code></div>
    </div>

    
    
<p>Welcome to <code>bayclumpr</code>! Before we get started with this
tutorial, we would like to remind you that there is an associated shiny
app that accompanies this <code>R</code> package. You can access
<code>BayClump</code> directly from your browser using by clicking <a href="https://bayclump.tripatilab.epss.ucla.edu/" class="external-link">here</a>. Now, let’s
go ahead and discuss some of the basic functions in
<code>bayclumpr</code>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://bayclump.tripatilab.epss.ucla.edu/" class="external-link">bayclumpr</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="performing-calibrations-using-bayclumpr">Performing calibrations using <code>bayclumpr</code><a class="anchor" aria-label="anchor" href="#performing-calibrations-using-bayclumpr"></a>
</h2>
<p>First, we will need some data to work with. We can use
<code>bayclumpr</code> to generate simulated datasets with uncertainty
values described in Roman-Palacios et al. (2022). For this example, we
will simulate 50 observations under a low-eror scenario. <strong>Note
that the functions in <code>bayclumpr</code> expect users to provide
uncertainty in terms of standard deviation.</strong> The resulting
dataset will be stored in the <code>ds</code> object.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ds</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cal.dataset.html">cal.dataset</a></span><span class="op">(</span>error <span class="op">=</span> <span class="st">"S1"</span>, nobs <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">ds</span><span class="op">)</span></span>
<span><span class="co">#&gt;      x_TRUE Temperature    TempError    y_TRUE      D47error       D47 Material</span></span>
<span><span class="co">#&gt; 1 10.076133   10.089943  0.013809939 0.6475262 -0.0032283733 0.6442978        1</span></span>
<span><span class="co">#&gt; 2 11.414949   11.399569 -0.015379377 0.6841481  0.0065876134 0.6907357        1</span></span>
<span><span class="co">#&gt; 3 12.517576   12.522651  0.005074617 0.7430624  0.0012176807 0.7442800        1</span></span>
<span><span class="co">#&gt; 4  9.695736    9.662728 -0.033008011 0.6333012  0.0021347308 0.6354360        1</span></span>
<span><span class="co">#&gt; 5 12.391566   12.364749 -0.026817078 0.7379670  0.0027211068 0.7406881        1</span></span>
<span><span class="co">#&gt; 6 12.060248   12.051630 -0.008617473 0.7206252  0.0005650349 0.7211903        1</span></span></code></pre></div>
<p>Now, let’s start by fitting different models in the simulated
dataset. For instance, let’s fit a Deming regression model using the
<code>cal.deming</code> function in <code>bayclumpr</code>:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/cal.deming.html">cal.deming</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">ds</span>, replicates <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt;        alpha       beta</span></span>
<span><span class="co">#&gt; 1  0.2440497 0.03906877</span></span>
<span><span class="co">#&gt; 2  0.2614754 0.03670698</span></span>
<span><span class="co">#&gt; 3  0.2760968 0.03574009</span></span>
<span><span class="co">#&gt; 4  0.2419661 0.03857797</span></span>
<span><span class="co">#&gt; 5  0.2752911 0.03585697</span></span>
<span><span class="co">#&gt; 6  0.2526154 0.03764163</span></span>
<span><span class="co">#&gt; 7  0.2497403 0.03784485</span></span>
<span><span class="co">#&gt; 8  0.2505127 0.03785190</span></span>
<span><span class="co">#&gt; 9  0.2590315 0.03708834</span></span>
<span><span class="co">#&gt; 10 0.2057244 0.04158558</span></span></code></pre></div>
<p>Alternatively, you can fit an unweighted or weighted OLS regression
using <code>cal.ols</code> and <code>cal.wols</code> functions,
respectively:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/cal.ols.html">cal.ols</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">ds</span>, replicates <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt;        alpha       beta</span></span>
<span><span class="co">#&gt; 1  0.2839352 0.03554307</span></span>
<span><span class="co">#&gt; 2  0.2872762 0.03527608</span></span>
<span><span class="co">#&gt; 3  0.2733101 0.03642586</span></span>
<span><span class="co">#&gt; 4  0.2640842 0.03709674</span></span>
<span><span class="co">#&gt; 5  0.2652946 0.03701428</span></span>
<span><span class="co">#&gt; 6  0.2668595 0.03679151</span></span>
<span><span class="co">#&gt; 7  0.2660233 0.03687870</span></span>
<span><span class="co">#&gt; 8  0.2826984 0.03542715</span></span>
<span><span class="co">#&gt; 9  0.2693398 0.03663859</span></span>
<span><span class="co">#&gt; 10 0.2850873 0.03507551</span></span>
<span><span class="fu"><a href="../reference/cal.wols.html">cal.wols</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">ds</span>, replicates <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt;        alpha       beta</span></span>
<span><span class="co">#&gt; 1  0.2557905 0.03789321</span></span>
<span><span class="co">#&gt; 2  0.2734807 0.03632590</span></span>
<span><span class="co">#&gt; 3  0.2716440 0.03643221</span></span>
<span><span class="co">#&gt; 4  0.2711929 0.03621119</span></span>
<span><span class="co">#&gt; 5  0.2743809 0.03625556</span></span>
<span><span class="co">#&gt; 6  0.2716777 0.03629290</span></span>
<span><span class="co">#&gt; 7  0.2765445 0.03604140</span></span>
<span><span class="co">#&gt; 8  0.2747726 0.03619440</span></span>
<span><span class="co">#&gt; 9  0.2710448 0.03650991</span></span>
<span><span class="co">#&gt; 10 0.2699076 0.03685035</span></span></code></pre></div>
<p>York regression models are also implemented in
<code>bayclumpr</code>:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/cal.york.html">cal.york</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">ds</span>, replicates <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt;        alpha       beta</span></span>
<span><span class="co">#&gt; 1  0.2502012 0.03822585</span></span>
<span><span class="co">#&gt; 2  0.2417208 0.03889872</span></span>
<span><span class="co">#&gt; 3  0.2430982 0.03835195</span></span>
<span><span class="co">#&gt; 4  0.2689329 0.03625636</span></span>
<span><span class="co">#&gt; 5  0.2714125 0.03611063</span></span>
<span><span class="co">#&gt; 6  0.2638400 0.03685362</span></span>
<span><span class="co">#&gt; 7  0.2897728 0.03520313</span></span>
<span><span class="co">#&gt; 8  0.2755461 0.03600768</span></span>
<span><span class="co">#&gt; 9  0.2630668 0.03715828</span></span>
<span><span class="co">#&gt; 10 0.2678943 0.03654801</span></span></code></pre></div>
<p>Finally, <code>bayclumpr</code> implements three types of Bayesian
linear models that are used for calibrations and temperature
reconstructions. Let’s fit all three models using the
<code>cal.bayesian</code> function:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">BayesCal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cal.bayesian.html">cal.bayesian</a></span><span class="op">(</span>calibrationData <span class="op">=</span> <span class="va">ds</span><span class="op">)</span></span></code></pre></div>
<p>The results are here stored in the <code>BayesCal</code> object and
corresponds to <code>stan</code> objects summarizing posterior
distributions of the parameters:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">BayesCal</span></span>
<span><span class="co">#&gt; $BLM1_fit</span></span>
<span><span class="co">#&gt; Inference for Stan model: anon_model.</span></span>
<span><span class="co">#&gt; 2 chains, each with iter=2500; warmup=1000; thin=1; </span></span>
<span><span class="co">#&gt; post-warmup draws per chain=1500, total post-warmup draws=3000.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;               mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat</span></span>
<span><span class="co">#&gt; alpha         0.27    0.00 0.01   0.24   0.26   0.27   0.27   0.29  2566    1</span></span>
<span><span class="co">#&gt; beta          0.04    0.00 0.00   0.03   0.04   0.04   0.04   0.04  2593    1</span></span>
<span><span class="co">#&gt; sigma         0.01    0.00 0.00   0.01   0.01   0.01   0.01   0.02  3138    1</span></span>
<span><span class="co">#&gt; log_lik[1]    3.29    0.00 0.13   3.01   3.21   3.30   3.37   3.51  2588    1</span></span>
<span><span class="co">#&gt; log_lik[2]    3.34    0.00 0.11   3.12   3.27   3.34   3.42   3.54  2970    1</span></span>
<span><span class="co">#&gt; log_lik[3]    2.71    0.00 0.18   2.31   2.59   2.72   2.83   3.02  2638    1</span></span>
<span><span class="co">#&gt; log_lik[4]    2.95    0.00 0.21   2.47   2.82   2.97   3.09   3.30  2742    1</span></span>
<span><span class="co">#&gt; log_lik[5]    2.50    0.00 0.21   2.03   2.37   2.52   2.65   2.87  2838    1</span></span>
<span><span class="co">#&gt; log_lik[6]    3.11    0.00 0.12   2.85   3.03   3.11   3.19   3.33  2636    1</span></span>
<span><span class="co">#&gt; log_lik[7]    3.31    0.00 0.11   3.09   3.24   3.31   3.39   3.50  2921    1</span></span>
<span><span class="co">#&gt; log_lik[8]    1.50    0.01 0.51   0.38   1.19   1.55   1.87   2.39  3203    1</span></span>
<span><span class="co">#&gt; log_lik[9]    3.01    0.00 0.19   2.59   2.89   3.03   3.15   3.33  2844    1</span></span>
<span><span class="co">#&gt; log_lik[10]   2.81    0.00 0.26   2.20   2.66   2.84   2.99   3.23  2904    1</span></span>
<span><span class="co">#&gt; log_lik[11]   3.25    0.00 0.12   3.00   3.18   3.25   3.33   3.46  2985    1</span></span>
<span><span class="co">#&gt; log_lik[12]   3.36    0.00 0.11   3.12   3.29   3.36   3.43   3.56  2855    1</span></span>
<span><span class="co">#&gt; log_lik[13]   3.36    0.00 0.11   3.14   3.29   3.36   3.43   3.56  3039    1</span></span>
<span><span class="co">#&gt; log_lik[14]   1.60    0.01 0.39   0.76   1.35   1.63   1.87   2.26  3173    1</span></span>
<span><span class="co">#&gt; log_lik[15]   3.33    0.00 0.11   3.11   3.26   3.33   3.40   3.53  3042    1</span></span>
<span><span class="co">#&gt; log_lik[16]   3.36    0.00 0.11   3.14   3.29   3.36   3.43   3.55  3091    1</span></span>
<span><span class="co">#&gt; log_lik[17]   3.30    0.00 0.12   3.03   3.22   3.31   3.38   3.52  2626    1</span></span>
<span><span class="co">#&gt; log_lik[18]   3.37    0.00 0.11   3.14   3.30   3.37   3.44   3.57  2986    1</span></span>
<span><span class="co">#&gt; log_lik[19]   3.25    0.00 0.14   2.91   3.16   3.26   3.35   3.48  3035    1</span></span>
<span><span class="co">#&gt; log_lik[20]   3.34    0.00 0.11   3.12   3.27   3.34   3.41   3.53  3005    1</span></span>
<span><span class="co">#&gt; log_lik[21]   2.58    0.00 0.22   2.09   2.45   2.60   2.74   2.96  2731    1</span></span>
<span><span class="co">#&gt; log_lik[22]   3.31    0.00 0.12   3.04   3.23   3.32   3.39   3.53  2631    1</span></span>
<span><span class="co">#&gt; log_lik[23]   3.21    0.00 0.11   2.97   3.14   3.22   3.29   3.42  2728    1</span></span>
<span><span class="co">#&gt; log_lik[24]   3.23    0.00 0.16   2.85   3.15   3.25   3.34   3.48  2822    1</span></span>
<span><span class="co">#&gt; log_lik[25]   3.18    0.00 0.12   2.91   3.11   3.19   3.26   3.41  2655    1</span></span>
<span><span class="co">#&gt; log_lik[26]   3.27    0.00 0.11   3.04   3.20   3.28   3.35   3.48  2986    1</span></span>
<span><span class="co">#&gt; log_lik[27]   3.04    0.00 0.19   2.58   2.93   3.06   3.18   3.36  2752    1</span></span>
<span><span class="co">#&gt; log_lik[28]   2.99    0.00 0.19   2.56   2.88   3.01   3.13   3.31  2794    1</span></span>
<span><span class="co">#&gt; log_lik[29]   1.83    0.01 0.34   1.08   1.62   1.85   2.07   2.41  3005    1</span></span>
<span><span class="co">#&gt; log_lik[30]   2.87    0.00 0.22   2.38   2.74   2.90   3.03   3.24  2779    1</span></span>
<span><span class="co">#&gt; log_lik[31]   3.11    0.00 0.16   2.75   3.01   3.12   3.22   3.38  2801    1</span></span>
<span><span class="co">#&gt; log_lik[32]   3.36    0.00 0.11   3.13   3.29   3.36   3.43   3.56  2948    1</span></span>
<span><span class="co">#&gt; log_lik[33]   2.20    0.01 0.32   1.48   2.01   2.23   2.44   2.74  2928    1</span></span>
<span><span class="co">#&gt; log_lik[34]   2.32    0.01 0.29   1.67   2.14   2.35   2.53   2.83  3076    1</span></span>
<span><span class="co">#&gt; log_lik[35]   3.37    0.00 0.11   3.14   3.30   3.37   3.44   3.57  3027    1</span></span>
<span><span class="co">#&gt; log_lik[36]   0.85    0.01 0.58  -0.40   0.49   0.90   1.26   1.83  3258    1</span></span>
<span><span class="co">#&gt; log_lik[37]   2.65    0.01 0.31   1.93   2.48   2.69   2.87   3.15  2913    1</span></span>
<span><span class="co">#&gt; log_lik[38]   3.22    0.00 0.11   2.99   3.15   3.23   3.30   3.42  2977    1</span></span>
<span><span class="co">#&gt; log_lik[39]   3.09    0.00 0.16   2.74   2.99   3.10   3.20   3.35  2906    1</span></span>
<span><span class="co">#&gt; log_lik[40]   3.08    0.00 0.16   2.73   2.99   3.10   3.19   3.36  2779    1</span></span>
<span><span class="co">#&gt; log_lik[41]   2.65    0.00 0.24   2.10   2.51   2.67   2.81   3.04  3034    1</span></span>
<span><span class="co">#&gt; log_lik[42]   1.71    0.01 0.37   0.89   1.47   1.74   1.97   2.35  2971    1</span></span>
<span><span class="co">#&gt; log_lik[43]   3.11    0.00 0.22   2.58   3.00   3.15   3.27   3.45  2603    1</span></span>
<span><span class="co">#&gt; log_lik[44]   3.37    0.00 0.11   3.13   3.30   3.37   3.44   3.57  2949    1</span></span>
<span><span class="co">#&gt; log_lik[45]   2.30    0.00 0.26   1.71   2.15   2.32   2.48   2.75  3088    1</span></span>
<span><span class="co">#&gt; log_lik[46]   3.29    0.00 0.16   2.88   3.22   3.32   3.40   3.55  1936    1</span></span>
<span><span class="co">#&gt; log_lik[47]   2.84    0.00 0.15   2.50   2.75   2.85   2.95   3.12  2728    1</span></span>
<span><span class="co">#&gt; log_lik[48]   3.20    0.00 0.16   2.84   3.10   3.21   3.31   3.46  2639    1</span></span>
<span><span class="co">#&gt; log_lik[49]   2.08    0.01 0.30   1.43   1.90   2.10   2.29   2.58  3158    1</span></span>
<span><span class="co">#&gt; log_lik[50]   3.30    0.00 0.12   3.02   3.22   3.30   3.38   3.52  2666    1</span></span>
<span><span class="co">#&gt; lp__        136.49    0.14 5.13 125.45 133.17 136.81 140.20 145.80  1332    1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Samples were drawn using NUTS(diag_e) at Tue Jul 22 08:17:58 2025.</span></span>
<span><span class="co">#&gt; For each parameter, n_eff is a crude measure of effective sample size,</span></span>
<span><span class="co">#&gt; and Rhat is the potential scale reduction factor on split chains (at </span></span>
<span><span class="co">#&gt; convergence, Rhat=1).</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $BLM1_fit_NoErrors</span></span>
<span><span class="co">#&gt; Inference for Stan model: anon_model.</span></span>
<span><span class="co">#&gt; 2 chains, each with iter=2500; warmup=1000; thin=1; </span></span>
<span><span class="co">#&gt; post-warmup draws per chain=1500, total post-warmup draws=3000.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;               mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat</span></span>
<span><span class="co">#&gt; alpha         0.27    0.00 0.01   0.24   0.26   0.27   0.28   0.29  1104    1</span></span>
<span><span class="co">#&gt; beta          0.04    0.00 0.00   0.03   0.04   0.04   0.04   0.04  1113    1</span></span>
<span><span class="co">#&gt; sigma         0.01    0.00 0.00   0.01   0.01   0.01   0.01   0.02   923    1</span></span>
<span><span class="co">#&gt; log_lik[1]    3.29    0.00 0.12   3.04   3.21   3.29   3.37   3.51  1229    1</span></span>
<span><span class="co">#&gt; log_lik[2]    3.34    0.00 0.10   3.12   3.27   3.34   3.41   3.54  1088    1</span></span>
<span><span class="co">#&gt; log_lik[3]    2.70    0.00 0.17   2.32   2.59   2.72   2.82   3.01  2779    1</span></span>
<span><span class="co">#&gt; log_lik[4]    2.95    0.01 0.20   2.53   2.82   2.97   3.09   3.28  1435    1</span></span>
<span><span class="co">#&gt; log_lik[5]    2.50    0.00 0.21   2.04   2.37   2.51   2.64   2.85  2387    1</span></span>
<span><span class="co">#&gt; log_lik[6]    3.11    0.00 0.11   2.87   3.03   3.11   3.18   3.32  2451    1</span></span>
<span><span class="co">#&gt; log_lik[7]    3.31    0.00 0.10   3.09   3.24   3.31   3.38   3.51  1220    1</span></span>
<span><span class="co">#&gt; log_lik[8]    1.51    0.01 0.51   0.40   1.19   1.56   1.88   2.37  1498    1</span></span>
<span><span class="co">#&gt; log_lik[9]    3.01    0.01 0.19   2.56   2.90   3.03   3.15   3.31  1312    1</span></span>
<span><span class="co">#&gt; log_lik[10]   2.80    0.01 0.26   2.22   2.63   2.83   2.99   3.22  1692    1</span></span>
<span><span class="co">#&gt; log_lik[11]   3.25    0.00 0.12   3.00   3.17   3.26   3.33   3.46  1065    1</span></span>
<span><span class="co">#&gt; log_lik[12]   3.36    0.00 0.11   3.14   3.29   3.36   3.43   3.56   893    1</span></span>
<span><span class="co">#&gt; log_lik[13]   3.36    0.00 0.11   3.14   3.29   3.37   3.43   3.56   901    1</span></span>
<span><span class="co">#&gt; log_lik[14]   1.59    0.01 0.38   0.72   1.35   1.62   1.86   2.24  1581    1</span></span>
<span><span class="co">#&gt; log_lik[15]   3.33    0.00 0.10   3.11   3.26   3.33   3.40   3.52  1029    1</span></span>
<span><span class="co">#&gt; log_lik[16]   3.36    0.00 0.10   3.14   3.29   3.36   3.43   3.55   924    1</span></span>
<span><span class="co">#&gt; log_lik[17]   3.30    0.00 0.12   3.06   3.22   3.30   3.38   3.52  1191    1</span></span>
<span><span class="co">#&gt; log_lik[18]   3.37    0.00 0.10   3.15   3.30   3.37   3.44   3.56   938    1</span></span>
<span><span class="co">#&gt; log_lik[19]   3.24    0.00 0.14   2.92   3.16   3.26   3.34   3.49  1197    1</span></span>
<span><span class="co">#&gt; log_lik[20]   3.34    0.00 0.10   3.12   3.27   3.34   3.41   3.53  1099    1</span></span>
<span><span class="co">#&gt; log_lik[21]   2.59    0.00 0.21   2.10   2.46   2.60   2.73   2.94  1926    1</span></span>
<span><span class="co">#&gt; log_lik[22]   3.31    0.00 0.11   3.07   3.23   3.31   3.39   3.52  1168    1</span></span>
<span><span class="co">#&gt; log_lik[23]   3.21    0.00 0.11   2.99   3.14   3.21   3.28   3.42  1725    1</span></span>
<span><span class="co">#&gt; log_lik[24]   3.23    0.01 0.16   2.84   3.14   3.25   3.34   3.49   969    1</span></span>
<span><span class="co">#&gt; log_lik[25]   3.18    0.00 0.11   2.94   3.10   3.18   3.26   3.40  1737    1</span></span>
<span><span class="co">#&gt; log_lik[26]   3.27    0.00 0.11   3.04   3.20   3.28   3.35   3.48  1018    1</span></span>
<span><span class="co">#&gt; log_lik[27]   3.03    0.00 0.19   2.60   2.91   3.06   3.17   3.34  1723    1</span></span>
<span><span class="co">#&gt; log_lik[28]   2.99    0.00 0.19   2.58   2.88   3.01   3.13   3.30  1755    1</span></span>
<span><span class="co">#&gt; log_lik[29]   1.83    0.01 0.33   1.08   1.65   1.87   2.06   2.38  2022    1</span></span>
<span><span class="co">#&gt; log_lik[30]   2.87    0.01 0.21   2.42   2.74   2.89   3.03   3.23  1448    1</span></span>
<span><span class="co">#&gt; log_lik[31]   3.10    0.00 0.16   2.75   3.00   3.12   3.21   3.37  1719    1</span></span>
<span><span class="co">#&gt; log_lik[32]   3.36    0.00 0.11   3.14   3.29   3.36   3.43   3.56   956    1</span></span>
<span><span class="co">#&gt; log_lik[33]   2.19    0.01 0.32   1.49   2.00   2.22   2.42   2.73  1815    1</span></span>
<span><span class="co">#&gt; log_lik[34]   2.33    0.01 0.29   1.72   2.15   2.35   2.54   2.81  1997    1</span></span>
<span><span class="co">#&gt; log_lik[35]   3.37    0.00 0.10   3.15   3.30   3.37   3.44   3.56   967    1</span></span>
<span><span class="co">#&gt; log_lik[36]   0.85    0.02 0.57  -0.42   0.49   0.91   1.27   1.83  1467    1</span></span>
<span><span class="co">#&gt; log_lik[37]   2.64    0.01 0.30   1.97   2.45   2.68   2.86   3.14  1653    1</span></span>
<span><span class="co">#&gt; log_lik[38]   3.22    0.00 0.11   3.01   3.16   3.23   3.30   3.42  1412    1</span></span>
<span><span class="co">#&gt; log_lik[39]   3.09    0.00 0.15   2.73   2.99   3.10   3.20   3.35  1308    1</span></span>
<span><span class="co">#&gt; log_lik[40]   3.09    0.00 0.15   2.76   2.99   3.10   3.19   3.34  1791    1</span></span>
<span><span class="co">#&gt; log_lik[41]   2.65    0.00 0.23   2.16   2.51   2.68   2.82   3.04  2122    1</span></span>
<span><span class="co">#&gt; log_lik[42]   1.71    0.01 0.36   0.89   1.51   1.74   1.96   2.31  1819    1</span></span>
<span><span class="co">#&gt; log_lik[43]   3.12    0.01 0.22   2.60   3.00   3.15   3.27   3.44  1365    1</span></span>
<span><span class="co">#&gt; log_lik[44]   3.37    0.00 0.11   3.15   3.29   3.37   3.44   3.56   937    1</span></span>
<span><span class="co">#&gt; log_lik[45]   2.29    0.01 0.25   1.72   2.14   2.31   2.47   2.72  2051    1</span></span>
<span><span class="co">#&gt; log_lik[46]   3.29    0.00 0.15   2.94   3.21   3.32   3.40   3.54   998    1</span></span>
<span><span class="co">#&gt; log_lik[47]   2.85    0.00 0.14   2.53   2.76   2.86   2.94   3.10  2862    1</span></span>
<span><span class="co">#&gt; log_lik[48]   3.20    0.00 0.15   2.86   3.11   3.22   3.30   3.45  1401    1</span></span>
<span><span class="co">#&gt; log_lik[49]   2.07    0.01 0.29   1.46   1.89   2.09   2.28   2.57  1560    1</span></span>
<span><span class="co">#&gt; log_lik[50]   3.30    0.00 0.11   3.06   3.22   3.30   3.38   3.52  1201    1</span></span>
<span><span class="co">#&gt; lp__        185.91    0.04 1.20 182.72 185.35 186.20 186.80 187.31   888    1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Samples were drawn using NUTS(diag_e) at Tue Jul 22 08:18:22 2025.</span></span>
<span><span class="co">#&gt; For each parameter, n_eff is a crude measure of effective sample size,</span></span>
<span><span class="co">#&gt; and Rhat is the potential scale reduction factor on split chains (at </span></span>
<span><span class="co">#&gt; convergence, Rhat=1).</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $BLM3_fit</span></span>
<span><span class="co">#&gt; Inference for Stan model: anon_model.</span></span>
<span><span class="co">#&gt; 2 chains, each with iter=2500; warmup=1000; thin=1; </span></span>
<span><span class="co">#&gt; post-warmup draws per chain=1500, total post-warmup draws=3000.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;               mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat</span></span>
<span><span class="co">#&gt; alpha[1]      0.27    0.00 0.01   0.24   0.26   0.27   0.27   0.29   979    1</span></span>
<span><span class="co">#&gt; beta[1]       0.04    0.00 0.00   0.03   0.04   0.04   0.04   0.04   981    1</span></span>
<span><span class="co">#&gt; sigma         0.01    0.00 0.00   0.01   0.01   0.01   0.01   0.02   926    1</span></span>
<span><span class="co">#&gt; log_lik[1]    3.29    0.00 0.12   3.02   3.22   3.30   3.37   3.51  1140    1</span></span>
<span><span class="co">#&gt; log_lik[2]    3.34    0.00 0.10   3.12   3.28   3.35   3.41   3.54  1021    1</span></span>
<span><span class="co">#&gt; log_lik[3]    2.71    0.00 0.19   2.30   2.59   2.72   2.84   3.02  2898    1</span></span>
<span><span class="co">#&gt; log_lik[4]    2.95    0.01 0.20   2.51   2.82   2.97   3.09   3.29  1434    1</span></span>
<span><span class="co">#&gt; log_lik[5]    2.50    0.00 0.22   2.03   2.37   2.52   2.66   2.87  2655    1</span></span>
<span><span class="co">#&gt; log_lik[6]    3.11    0.00 0.12   2.85   3.04   3.12   3.19   3.32  2390    1</span></span>
<span><span class="co">#&gt; log_lik[7]    3.31    0.00 0.11   3.09   3.24   3.32   3.38   3.51  1127    1</span></span>
<span><span class="co">#&gt; log_lik[8]    1.48    0.02 0.53   0.34   1.15   1.53   1.86   2.38  1212    1</span></span>
<span><span class="co">#&gt; log_lik[9]    3.01    0.01 0.19   2.58   2.89   3.03   3.15   3.32  1279    1</span></span>
<span><span class="co">#&gt; log_lik[10]   2.81    0.01 0.27   2.19   2.65   2.84   3.00   3.23  1385    1</span></span>
<span><span class="co">#&gt; log_lik[11]   3.25    0.00 0.12   3.00   3.17   3.25   3.33   3.46  1123    1</span></span>
<span><span class="co">#&gt; log_lik[12]   3.36    0.00 0.11   3.13   3.29   3.37   3.44   3.56   839    1</span></span>
<span><span class="co">#&gt; log_lik[13]   3.36    0.00 0.10   3.15   3.29   3.37   3.44   3.55   893    1</span></span>
<span><span class="co">#&gt; log_lik[14]   1.60    0.01 0.39   0.74   1.34   1.63   1.88   2.26  1673    1</span></span>
<span><span class="co">#&gt; log_lik[15]   3.33    0.00 0.11   3.12   3.26   3.33   3.40   3.52  1057    1</span></span>
<span><span class="co">#&gt; log_lik[16]   3.36    0.00 0.10   3.15   3.29   3.36   3.43   3.55   936    1</span></span>
<span><span class="co">#&gt; log_lik[17]   3.30    0.00 0.12   3.04   3.23   3.31   3.38   3.52  1104    1</span></span>
<span><span class="co">#&gt; log_lik[18]   3.37    0.00 0.10   3.15   3.30   3.37   3.44   3.56   907    1</span></span>
<span><span class="co">#&gt; log_lik[19]   3.25    0.00 0.14   2.91   3.17   3.26   3.35   3.48  1124    1</span></span>
<span><span class="co">#&gt; log_lik[20]   3.34    0.00 0.10   3.12   3.27   3.34   3.41   3.53  1027    1</span></span>
<span><span class="co">#&gt; log_lik[21]   2.58    0.00 0.22   2.10   2.44   2.60   2.73   2.95  1999    1</span></span>
<span><span class="co">#&gt; log_lik[22]   3.31    0.00 0.12   3.05   3.24   3.31   3.39   3.52  1084    1</span></span>
<span><span class="co">#&gt; log_lik[23]   3.21    0.00 0.11   2.98   3.15   3.22   3.29   3.42  1617    1</span></span>
<span><span class="co">#&gt; log_lik[24]   3.23    0.01 0.17   2.85   3.14   3.26   3.35   3.49   946    1</span></span>
<span><span class="co">#&gt; log_lik[25]   3.18    0.00 0.12   2.93   3.11   3.19   3.26   3.40  1666    1</span></span>
<span><span class="co">#&gt; log_lik[26]   3.27    0.00 0.11   3.03   3.20   3.28   3.35   3.48  1061    1</span></span>
<span><span class="co">#&gt; log_lik[27]   3.04    0.01 0.20   2.58   2.93   3.07   3.19   3.36  1350    1</span></span>
<span><span class="co">#&gt; log_lik[28]   2.98    0.01 0.20   2.55   2.86   3.00   3.12   3.32  1421    1</span></span>
<span><span class="co">#&gt; log_lik[29]   1.82    0.01 0.33   1.06   1.61   1.85   2.04   2.39  1766    1</span></span>
<span><span class="co">#&gt; log_lik[30]   2.87    0.01 0.21   2.41   2.74   2.89   3.03   3.23  1464    1</span></span>
<span><span class="co">#&gt; log_lik[31]   3.11    0.00 0.16   2.75   3.02   3.13   3.23   3.37  1430    1</span></span>
<span><span class="co">#&gt; log_lik[32]   3.36    0.00 0.11   3.14   3.29   3.36   3.43   3.56   914    1</span></span>
<span><span class="co">#&gt; log_lik[33]   2.21    0.01 0.33   1.48   2.00   2.24   2.44   2.75  1688    1</span></span>
<span><span class="co">#&gt; log_lik[34]   2.31    0.01 0.30   1.66   2.12   2.34   2.53   2.81  1524    1</span></span>
<span><span class="co">#&gt; log_lik[35]   3.37    0.00 0.10   3.15   3.30   3.37   3.44   3.56   934    1</span></span>
<span><span class="co">#&gt; log_lik[36]   0.82    0.02 0.59  -0.42   0.46   0.87   1.24   1.84  1238    1</span></span>
<span><span class="co">#&gt; log_lik[37]   2.65    0.01 0.31   1.93   2.47   2.69   2.88   3.15  1380    1</span></span>
<span><span class="co">#&gt; log_lik[38]   3.22    0.00 0.11   3.00   3.15   3.22   3.29   3.43  1490    1</span></span>
<span><span class="co">#&gt; log_lik[39]   3.09    0.00 0.16   2.75   2.99   3.10   3.20   3.35  1361    1</span></span>
<span><span class="co">#&gt; log_lik[40]   3.08    0.00 0.16   2.74   2.98   3.09   3.19   3.35  1539    1</span></span>
<span><span class="co">#&gt; log_lik[41]   2.64    0.01 0.24   2.11   2.49   2.66   2.81   3.05  1603    1</span></span>
<span><span class="co">#&gt; log_lik[42]   1.69    0.01 0.36   0.88   1.47   1.73   1.95   2.32  1645    1</span></span>
<span><span class="co">#&gt; log_lik[43]   3.11    0.01 0.22   2.59   2.98   3.14   3.26   3.45  1154    1</span></span>
<span><span class="co">#&gt; log_lik[44]   3.37    0.00 0.11   3.15   3.30   3.37   3.44   3.56   900    1</span></span>
<span><span class="co">#&gt; log_lik[45]   2.30    0.01 0.27   1.71   2.14   2.32   2.49   2.74  2187    1</span></span>
<span><span class="co">#&gt; log_lik[46]   3.30    0.01 0.15   2.91   3.22   3.31   3.40   3.54   729    1</span></span>
<span><span class="co">#&gt; log_lik[47]   2.84    0.00 0.15   2.51   2.74   2.86   2.94   3.11  3094    1</span></span>
<span><span class="co">#&gt; log_lik[48]   3.19    0.00 0.16   2.84   3.10   3.21   3.30   3.46  1252    1</span></span>
<span><span class="co">#&gt; log_lik[49]   2.08    0.01 0.30   1.44   1.89   2.10   2.29   2.58  1852    1</span></span>
<span><span class="co">#&gt; log_lik[50]   3.30    0.00 0.12   3.04   3.23   3.30   3.38   3.51  1117    1</span></span>
<span><span class="co">#&gt; lp__        185.86    0.05 1.28 182.51 185.34 186.19 186.76 187.29   696    1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Samples were drawn using NUTS(diag_e) at Tue Jul 22 08:18:47 2025.</span></span>
<span><span class="co">#&gt; For each parameter, n_eff is a crude measure of effective sample size,</span></span>
<span><span class="co">#&gt; and Rhat is the potential scale reduction factor on split chains (at </span></span>
<span><span class="co">#&gt; convergence, Rhat=1).</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attr(,"loo")</span></span>
<span><span class="co">#&gt;         elpd_diff se_diff</span></span>
<span><span class="co">#&gt; BLM1_NE  0.0       0.0   </span></span>
<span><span class="co">#&gt; BLM1_E   0.0       0.0   </span></span>
<span><span class="co">#&gt; BLM3    -0.1       0.1</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="reconstructing-temperatures-in-bayclumpr">Reconstructing temperatures in <code>bayclumpr</code><a class="anchor" aria-label="anchor" href="#reconstructing-temperatures-in-bayclumpr"></a>
</h2>
<p><code>bayclumpr</code> implements two functions to perform
temperature reconstructions under frequentist (<code>rec.clumped</code>)
and Bayesian frameworks (<code>rec.bayesian</code>). Let’s review how
each of these functions work by generating a synthetic dataset for two
samples.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">recData</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Sample <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"Sample"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">9</span><span class="op">)</span>,</span>
<span>                      D47 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,</span>
<span>                      D47error <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.005</span>,<span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.01</span>,<span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.02</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                      N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">9</span><span class="op">)</span>,</span>
<span>                      Material <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">9</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>As for the calibration step, <code>bayclumpr</code> expects
uncertainty (<code>D47error</code>) to be expressed in terms of standard
deviation. Note that the <code>recData</code> object generated above
includes the smallest number of columns that are needed to perform
reconstructions in <code>bayclumpr</code>.</p>
<p>From this point, we will need to either specify the distribution of
parameter estimates from the calibration step. For instance, let’s
assume that we were interested in reconstructing temperatures for our
<code>recData</code> under an OLS model. First, we would have to run our
calibration analyses:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">paramdist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cal.ols.html">cal.ols</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">ds</span>, replicates <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<p>From this point, we can use the <code>rec.clumped</code> to
reconstruct temperatures based on the reconstruction dataset
(<code>recData</code> argument) and the observed calibration object
(<code>obCal</code> argument):</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/rec.clumped.html">rec.clumped</a></span><span class="op">(</span>recData <span class="op">=</span> <span class="va">recData</span>, obCal <span class="op">=</span> <span class="va">paramdist</span><span class="op">)</span></span>
<span><span class="co">#&gt;     Sample D47 D47error  meanTemp    error</span></span>
<span><span class="co">#&gt; 1 Sample 1 0.6    0.005  60.03159 2.524450</span></span>
<span><span class="co">#&gt; 2 Sample 2 0.7    0.005  18.33601 1.694860</span></span>
<span><span class="co">#&gt; 3 Sample 3 0.8    0.005 -10.81881 1.237513</span></span>
<span><span class="co">#&gt; 4 Sample 4 0.6    0.010  60.03159 4.992374</span></span>
<span><span class="co">#&gt; 5 Sample 5 0.7    0.010  18.33601 3.360496</span></span>
<span><span class="co">#&gt; 6 Sample 6 0.8    0.010 -10.81881 2.457676</span></span>
<span><span class="co">#&gt; 7 Sample 7 0.6    0.020  60.03159 9.766853</span></span>
<span><span class="co">#&gt; 8 Sample 8 0.7    0.020  18.33601 6.607381</span></span>
<span><span class="co">#&gt; 9 Sample 9 0.8    0.020 -10.81881 4.847547</span></span></code></pre></div>
<p>The resulting object includes information from the template
reconstruction dataset but also information on the reconstructed
temperature and associated uncertainty (<code>1 SD</code>). Let’s now
perform reconstructions but under a Bayesian framework. For this, we
will again need parameter estimates derived from the calibration step
(see the <code>BayesCal</code> created above). We will perform
reconstructions under only a single of the Bayesian models equivalent to
the OLS but fit under a Bayesian framework
(<code>BayesCal$BLM1_fit_NoErrors</code>).</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">PredsBay</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/rec.bayesian.html">rec.bayesian</a></span><span class="op">(</span>calModel <span class="op">=</span> <span class="va">BayesCal</span><span class="op">$</span><span class="va">BLM1_fit_NoErrors</span>, recData <span class="op">=</span> <span class="va">recData</span>, iter <span class="op">=</span> <span class="fl">1000</span>, postcalsamples <span class="op">=</span> <span class="fl">100</span>, MC <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).</span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; Chain 1: Gradient evaluation took 4.9e-05 seconds</span></span>
<span><span class="co">#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.49 seconds.</span></span>
<span><span class="co">#&gt; Chain 1: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; Chain 1:  Elapsed Time: 0.459 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 1:                0.291 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1:                0.75 seconds (Total)</span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).</span></span>
<span><span class="co">#&gt; Chain 2: </span></span>
<span><span class="co">#&gt; Chain 2: Gradient evaluation took 2.7e-05 seconds</span></span>
<span><span class="co">#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.</span></span>
<span><span class="co">#&gt; Chain 2: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 2: </span></span>
<span><span class="co">#&gt; Chain 2: </span></span>
<span><span class="co">#&gt; Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: </span></span>
<span><span class="co">#&gt; Chain 2:  Elapsed Time: 0.384 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 2:                0.29 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2:                0.674 seconds (Total)</span></span>
<span><span class="co">#&gt; Chain 2:</span></span></code></pre></div>
<p>The associated reconstructions to this Bayesian model are shown
below:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">PredsBay</span></span>
<span><span class="co">#&gt;     Sample D47 D47error  meanTemp     error</span></span>
<span><span class="co">#&gt; 1 Sample 1 0.6    0.005  59.57497 0.7403076</span></span>
<span><span class="co">#&gt; 2 Sample 2 0.7    0.005  18.66416 0.5285738</span></span>
<span><span class="co">#&gt; 3 Sample 3 0.8    0.005 -10.12629 0.3530472</span></span>
<span><span class="co">#&gt; 4 Sample 4 0.6    0.010  59.55347 0.8024151</span></span>
<span><span class="co">#&gt; 5 Sample 5 0.7    0.010  18.63890 0.5782041</span></span>
<span><span class="co">#&gt; 6 Sample 6 0.8    0.010 -10.12668 0.4293646</span></span>
<span><span class="co">#&gt; 7 Sample 7 0.6    0.020  59.51917 1.2027646</span></span>
<span><span class="co">#&gt; 8 Sample 8 0.7    0.020  18.65469 0.8807962</span></span>
<span><span class="co">#&gt; 9 Sample 9 0.8    0.020 -10.12319 0.5602955</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="including-a-co-variate-with-error-in-the-covariate">Including a co-variate (with error in the covariate)<a class="anchor" aria-label="anchor" href="#including-a-co-variate-with-error-in-the-covariate"></a>
</h2>
<p>Now, instead of having a single predictor, we will use a second
column (i.e., Ion) and it’s error (i.e., IonError) as predictors. Let’s
first create a calibration dataset.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ds</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cal.dataset.html">cal.dataset</a></span><span class="op">(</span>error <span class="op">=</span> <span class="st">"S1"</span>, nobs <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></span></code></pre></div>
<p>Note that we will be using not super informative values for Ion and
its error. We just need to include those two new columns in the
dataset:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ds</span><span class="op">$</span><span class="va">Ion</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">ds</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">ds</span><span class="op">$</span><span class="va">IonError</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">ds</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p>At this point, we can fit the regression model that accounts for
uncertainty in each of the two predictors</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ionmodel</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cal.ion.bayesian.html">cal.ion.bayesian</a></span><span class="op">(</span>calibrationData <span class="op">=</span> <span class="va">ds</span>, useIonError <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">ionmodel</span></span>
<span><span class="co">#&gt; $BLM1_fit</span></span>
<span><span class="co">#&gt; Inference for Stan model: anon_model.</span></span>
<span><span class="co">#&gt; 2 chains, each with iter=2500; warmup=1000; thin=1; </span></span>
<span><span class="co">#&gt; post-warmup draws per chain=1500, total post-warmup draws=3000.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;        mean se_mean   sd  2.5%   25%   50%    75%  97.5% n_eff Rhat</span></span>
<span><span class="co">#&gt; alpha  0.27    0.00 0.01  0.24  0.26  0.27   0.28   0.30  6450    1</span></span>
<span><span class="co">#&gt; beta   0.04    0.00 0.00  0.03  0.04  0.04   0.04   0.04  6339    1</span></span>
<span><span class="co">#&gt; gamma  0.00    0.00 0.00 -0.01  0.00  0.00   0.00   0.00  1793    1</span></span>
<span><span class="co">#&gt; sigma  0.01    0.00 0.00  0.01  0.01  0.01   0.01   0.02  4431    1</span></span>
<span><span class="co">#&gt; lp__  99.57    0.26 7.16 84.74 94.80 99.82 104.67 112.48   776    1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Samples were drawn using NUTS(diag_e) at Tue Jul 22 08:19:38 2025.</span></span>
<span><span class="co">#&gt; For each parameter, n_eff is a crude measure of effective sample size,</span></span>
<span><span class="co">#&gt; and Rhat is the potential scale reduction factor on split chains (at </span></span>
<span><span class="co">#&gt; convergence, Rhat=1).</span></span></code></pre></div>
<p>From here, we can simply run a reconstruction based on a synthetic
reconstruction dataset with the following structure:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">recData</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Sample <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"Sample"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">9</span><span class="op">)</span>,</span>
<span>                      D47 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,</span>
<span>                      D47error <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.005</span>,<span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.01</span>,<span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.02</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                      Ion <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,</span>
<span>                      IonError <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.005</span>,<span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.01</span>,<span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.02</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                      N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">9</span><span class="op">)</span>,</span>
<span>                      Material <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">9</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The reconstruction can be performed as follows:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">PredsBay</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/rec.ion.bayesian.html">rec.ion.bayesian</a></span><span class="op">(</span>calModel <span class="op">=</span> <span class="va">ionmodel</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>,</span>
<span>                         recData <span class="op">=</span> <span class="va">recData</span>,</span>
<span>                         iter <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>                         postcalsamples <span class="op">=</span> <span class="fl">100</span>, MC <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).</span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; Chain 1: Gradient evaluation took 5.7e-05 seconds</span></span>
<span><span class="co">#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.57 seconds.</span></span>
<span><span class="co">#&gt; Chain 1: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; Chain 1:  Elapsed Time: 0.575 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 1:                0.323 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1:                0.898 seconds (Total)</span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).</span></span>
<span><span class="co">#&gt; Chain 2: </span></span>
<span><span class="co">#&gt; Chain 2: Gradient evaluation took 3e-05 seconds</span></span>
<span><span class="co">#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.3 seconds.</span></span>
<span><span class="co">#&gt; Chain 2: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 2: </span></span>
<span><span class="co">#&gt; Chain 2: </span></span>
<span><span class="co">#&gt; Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: </span></span>
<span><span class="co">#&gt; Chain 2:  Elapsed Time: 0.534 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 2:                0.634 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2:                1.168 seconds (Total)</span></span>
<span><span class="co">#&gt; Chain 2:</span></span></code></pre></div>
<p>And the resulting reconstructions are as follow:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">PredsBay</span></span>
<span><span class="co">#&gt;     Sample D47 D47error  meanTemp     error</span></span>
<span><span class="co">#&gt; 1 Sample 1 0.6    0.005  59.83046  7.665063</span></span>
<span><span class="co">#&gt; 2 Sample 2 0.7    0.005  18.44528  5.025854</span></span>
<span><span class="co">#&gt; 3 Sample 3 0.8    0.005 -10.52767  3.740377</span></span>
<span><span class="co">#&gt; 4 Sample 4 0.6    0.010  59.90502  8.854410</span></span>
<span><span class="co">#&gt; 5 Sample 5 0.7    0.010  18.50280  5.825532</span></span>
<span><span class="co">#&gt; 6 Sample 6 0.8    0.010 -10.49236  4.318791</span></span>
<span><span class="co">#&gt; 7 Sample 7 0.6    0.020  60.25275 12.588328</span></span>
<span><span class="co">#&gt; 8 Sample 8 0.7    0.020  18.72431  8.353161</span></span>
<span><span class="co">#&gt; 9 Sample 9 0.8    0.020 -10.40502  6.101526</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="including-a-co-variate-without-error-in-the-covariate">Including a co-variate (without error in the covariate)<a class="anchor" aria-label="anchor" href="#including-a-co-variate-without-error-in-the-covariate"></a>
</h2>
<p>We will now do the same for the models outlined above but ignoring
uncertainty in the covariate (Ion):</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ds</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cal.dataset.html">cal.dataset</a></span><span class="op">(</span>error <span class="op">=</span> <span class="st">"S1"</span>, nobs <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">ds</span><span class="op">$</span><span class="va">Ion</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">ds</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">ionmodel</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cal.ion.bayesian.html">cal.ion.bayesian</a></span><span class="op">(</span>calibrationData <span class="op">=</span> <span class="va">ds</span>, useIonError <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">ionmodel</span></span>
<span><span class="co">#&gt; $BLM1_fit</span></span>
<span><span class="co">#&gt; Inference for Stan model: anon_model.</span></span>
<span><span class="co">#&gt; 2 chains, each with iter=2500; warmup=1000; thin=1; </span></span>
<span><span class="co">#&gt; post-warmup draws per chain=1500, total post-warmup draws=3000.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;         mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat</span></span>
<span><span class="co">#&gt; alpha   0.27    0.00 0.01   0.25   0.26   0.27   0.28   0.30  2908    1</span></span>
<span><span class="co">#&gt; beta    0.04    0.00 0.00   0.03   0.04   0.04   0.04   0.04  2931    1</span></span>
<span><span class="co">#&gt; gamma   0.00    0.00 0.00   0.00   0.00   0.00   0.00   0.00  5064    1</span></span>
<span><span class="co">#&gt; sigma   0.01    0.00 0.00   0.01   0.01   0.01   0.01   0.02  2766    1</span></span>
<span><span class="co">#&gt; lp__  136.05    0.14 5.24 124.71 132.76 136.44 139.86 145.28  1500    1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Samples were drawn using NUTS(diag_e) at Tue Jul 22 08:20:27 2025.</span></span>
<span><span class="co">#&gt; For each parameter, n_eff is a crude measure of effective sample size,</span></span>
<span><span class="co">#&gt; and Rhat is the potential scale reduction factor on split chains (at </span></span>
<span><span class="co">#&gt; convergence, Rhat=1).</span></span></code></pre></div>
<p>From here, we can just run the reconstructions</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">recData</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Sample <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"Sample"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">9</span><span class="op">)</span>,</span>
<span>                      D47 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,</span>
<span>                      D47error <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.005</span>,<span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.01</span>,<span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.02</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                      Ion <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,</span>
<span>                      N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">9</span><span class="op">)</span>,</span>
<span>                      Material <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">9</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">PredsBay</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/rec.ion.bayesian.html">rec.ion.bayesian</a></span><span class="op">(</span>calModel <span class="op">=</span> <span class="va">ionmodel</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>,</span>
<span>                             recData <span class="op">=</span> <span class="va">recData</span>,</span>
<span>                             iter <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>                             postcalsamples <span class="op">=</span> <span class="fl">100</span>, MC <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                             useIonError <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).</span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; Chain 1: Gradient evaluation took 6.4e-05 seconds</span></span>
<span><span class="co">#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.64 seconds.</span></span>
<span><span class="co">#&gt; Chain 1: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; Chain 1:  Elapsed Time: 0.48 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 1:                0.322 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1:                0.802 seconds (Total)</span></span>
<span><span class="co">#&gt; Chain 1: </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).</span></span>
<span><span class="co">#&gt; Chain 2: </span></span>
<span><span class="co">#&gt; Chain 2: Gradient evaluation took 3e-05 seconds</span></span>
<span><span class="co">#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.3 seconds.</span></span>
<span><span class="co">#&gt; Chain 2: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 2: </span></span>
<span><span class="co">#&gt; Chain 2: </span></span>
<span><span class="co">#&gt; Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2: </span></span>
<span><span class="co">#&gt; Chain 2:  Elapsed Time: 0.46 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 2:                0.594 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2:                1.054 seconds (Total)</span></span>
<span><span class="co">#&gt; Chain 2:</span></span>
<span></span>
<span><span class="va">PredsBay</span></span>
<span><span class="co">#&gt;     Sample D47 D47error  meanTemp     error</span></span>
<span><span class="co">#&gt; 1 Sample 1 0.6    0.005  60.50896  7.835126</span></span>
<span><span class="co">#&gt; 2 Sample 2 0.7    0.005  18.71759  5.071897</span></span>
<span><span class="co">#&gt; 3 Sample 3 0.8    0.005 -10.46470  3.745609</span></span>
<span><span class="co">#&gt; 4 Sample 4 0.6    0.010  60.56685  9.001496</span></span>
<span><span class="co">#&gt; 5 Sample 5 0.7    0.010  18.76788  5.894212</span></span>
<span><span class="co">#&gt; 6 Sample 6 0.8    0.010 -10.43113  4.367098</span></span>
<span><span class="co">#&gt; 7 Sample 7 0.6    0.020  60.91822 12.720127</span></span>
<span><span class="co">#&gt; 8 Sample 8 0.7    0.020  18.95777  8.401952</span></span>
<span><span class="co">#&gt; 9 Sample 9 0.8    0.020 -10.33175  6.151552</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="outlook">Outlook<a class="anchor" aria-label="anchor" href="#outlook"></a>
</h2>
<p>We have reviewed the most fundamental aspects of using
<code>bayclumpr</code>. More advances analyses involving alternative
priors in Bayesian models are an option.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Cristian Roman Palacios, Hannah M. Carroll, Aradhna Tripati.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
