[{"path":"https://tripati-lab.github.io/bayclumpr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 bayclumpr authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/articles/bayclumpr.html","id":"performing-calibrations-using-bayclumpr","dir":"Articles","previous_headings":"","what":"Performing calibrations using bayclumpr","title":"bayclumpr","text":"First, need data work . can use bayclumpr generate simulated datasets uncertainty values described Roman-Palacios et al. (2022). example, simulate 50 observations low-eror scenario. Note functions bayclumpr expect users provide uncertainty terms standard deviation. resulting dataset stored ds object. Now, let’s start fitting different models simulated dataset. instance, let’s fit Deming regression model using cal.deming function bayclumpr: Alternatively, can fit unweighted weighted OLS regression using cal.ols cal.wols functions, respectively: York regression models also implemented bayclumpr: Finally, bayclumpr implements three types Bayesian linear models used calibrations temperature reconstructions. Let’s fit three models using cal.bayesian function: results stored BayesCal object corresponds stan objects summarizing posterior distributions parameters:","code":"ds <- cal.dataset(error = \"S1\", nobs = 50) head(ds) #>      x_TRUE Temperature    TempError    y_TRUE      D47error       D47 Material #> 1 10.076133   10.089943  0.013809939 0.6475262 -0.0032283733 0.6442978        1 #> 2 11.414949   11.399569 -0.015379377 0.6841481  0.0065876134 0.6907357        1 #> 3 12.517576   12.522651  0.005074617 0.7430624  0.0012176807 0.7442800        1 #> 4  9.695736    9.662728 -0.033008011 0.6333012  0.0021347308 0.6354360        1 #> 5 12.391566   12.364749 -0.026817078 0.7379670  0.0027211068 0.7406881        1 #> 6 12.060248   12.051630 -0.008617473 0.7206252  0.0005650349 0.7211903        1 cal.deming(data = ds, replicates = 10) #>        alpha       beta #> 1  0.2440497 0.03906877 #> 2  0.2614754 0.03670698 #> 3  0.2760968 0.03574009 #> 4  0.2419661 0.03857797 #> 5  0.2752911 0.03585697 #> 6  0.2526154 0.03764163 #> 7  0.2497403 0.03784485 #> 8  0.2505127 0.03785190 #> 9  0.2590315 0.03708834 #> 10 0.2057244 0.04158558 cal.ols(data = ds, replicates = 10) #>        alpha       beta #> 1  0.2839352 0.03554307 #> 2  0.2872762 0.03527608 #> 3  0.2733101 0.03642586 #> 4  0.2640842 0.03709674 #> 5  0.2652946 0.03701428 #> 6  0.2668595 0.03679151 #> 7  0.2660233 0.03687870 #> 8  0.2826984 0.03542715 #> 9  0.2693398 0.03663859 #> 10 0.2850873 0.03507551 cal.wols(data = ds, replicates = 10) #>        alpha       beta #> 1  0.2557905 0.03789321 #> 2  0.2734807 0.03632590 #> 3  0.2716440 0.03643221 #> 4  0.2711929 0.03621119 #> 5  0.2743809 0.03625556 #> 6  0.2716777 0.03629290 #> 7  0.2765445 0.03604140 #> 8  0.2747726 0.03619440 #> 9  0.2710448 0.03650991 #> 10 0.2699076 0.03685035 cal.york(data = ds, replicates = 10) #>        alpha       beta #> 1  0.2502012 0.03822585 #> 2  0.2417208 0.03889872 #> 3  0.2430982 0.03835195 #> 4  0.2689329 0.03625636 #> 5  0.2714125 0.03611063 #> 6  0.2638400 0.03685362 #> 7  0.2897728 0.03520313 #> 8  0.2755461 0.03600768 #> 9  0.2630668 0.03715828 #> 10 0.2678943 0.03654801 BayesCal <- cal.bayesian(calibrationData = ds, numSavedSteps = 3000, priors = \"Weak\", MC = FALSE) #>  #> SAMPLING FOR MODEL 'cc8e49c029f748bb6dab815288864757' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 3.2e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2500 [  0%]  (Warmup) #> Chain 1: Iteration:  250 / 2500 [ 10%]  (Warmup) #> Chain 1: Iteration:  500 / 2500 [ 20%]  (Warmup) #> Chain 1: Iteration:  750 / 2500 [ 30%]  (Warmup) #> Chain 1: Iteration: 1000 / 2500 [ 40%]  (Warmup) #> Chain 1: Iteration: 1001 / 2500 [ 40%]  (Sampling) #> Chain 1: Iteration: 1250 / 2500 [ 50%]  (Sampling) #> Chain 1: Iteration: 1500 / 2500 [ 60%]  (Sampling) #> Chain 1: Iteration: 1750 / 2500 [ 70%]  (Sampling) #> Chain 1: Iteration: 2000 / 2500 [ 80%]  (Sampling) #> Chain 1: Iteration: 2250 / 2500 [ 90%]  (Sampling) #> Chain 1: Iteration: 2500 / 2500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.717123 seconds (Warm-up) #> Chain 1:                0.702545 seconds (Sampling) #> Chain 1:                1.41967 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'cc8e49c029f748bb6dab815288864757' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.3e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2500 [  0%]  (Warmup) #> Chain 2: Iteration:  250 / 2500 [ 10%]  (Warmup) #> Chain 2: Iteration:  500 / 2500 [ 20%]  (Warmup) #> Chain 2: Iteration:  750 / 2500 [ 30%]  (Warmup) #> Chain 2: Iteration: 1000 / 2500 [ 40%]  (Warmup) #> Chain 2: Iteration: 1001 / 2500 [ 40%]  (Sampling) #> Chain 2: Iteration: 1250 / 2500 [ 50%]  (Sampling) #> Chain 2: Iteration: 1500 / 2500 [ 60%]  (Sampling) #> Chain 2: Iteration: 1750 / 2500 [ 70%]  (Sampling) #> Chain 2: Iteration: 2000 / 2500 [ 80%]  (Sampling) #> Chain 2: Iteration: 2250 / 2500 [ 90%]  (Sampling) #> Chain 2: Iteration: 2500 / 2500 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.326322 seconds (Warm-up) #> Chain 2:                0.630451 seconds (Sampling) #> Chain 2:                0.956773 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL '7f9086b208f04841e16d509c43ea0782' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.7e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2500 [  0%]  (Warmup) #> Chain 1: Iteration:  250 / 2500 [ 10%]  (Warmup) #> Chain 1: Iteration:  500 / 2500 [ 20%]  (Warmup) #> Chain 1: Iteration:  750 / 2500 [ 30%]  (Warmup) #> Chain 1: Iteration: 1000 / 2500 [ 40%]  (Warmup) #> Chain 1: Iteration: 1001 / 2500 [ 40%]  (Sampling) #> Chain 1: Iteration: 1250 / 2500 [ 50%]  (Sampling) #> Chain 1: Iteration: 1500 / 2500 [ 60%]  (Sampling) #> Chain 1: Iteration: 1750 / 2500 [ 70%]  (Sampling) #> Chain 1: Iteration: 2000 / 2500 [ 80%]  (Sampling) #> Chain 1: Iteration: 2250 / 2500 [ 90%]  (Sampling) #> Chain 1: Iteration: 2500 / 2500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.339182 seconds (Warm-up) #> Chain 1:                0.293246 seconds (Sampling) #> Chain 1:                0.632428 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL '7f9086b208f04841e16d509c43ea0782' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2500 [  0%]  (Warmup) #> Chain 2: Iteration:  250 / 2500 [ 10%]  (Warmup) #> Chain 2: Iteration:  500 / 2500 [ 20%]  (Warmup) #> Chain 2: Iteration:  750 / 2500 [ 30%]  (Warmup) #> Chain 2: Iteration: 1000 / 2500 [ 40%]  (Warmup) #> Chain 2: Iteration: 1001 / 2500 [ 40%]  (Sampling) #> Chain 2: Iteration: 1250 / 2500 [ 50%]  (Sampling) #> Chain 2: Iteration: 1500 / 2500 [ 60%]  (Sampling) #> Chain 2: Iteration: 1750 / 2500 [ 70%]  (Sampling) #> Chain 2: Iteration: 2000 / 2500 [ 80%]  (Sampling) #> Chain 2: Iteration: 2250 / 2500 [ 90%]  (Sampling) #> Chain 2: Iteration: 2500 / 2500 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.356504 seconds (Warm-up) #> Chain 2:                0.301817 seconds (Sampling) #> Chain 2:                0.658321 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL '006ab23433c79b9b7b0940468909174a' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.5e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2500 [  0%]  (Warmup) #> Chain 1: Iteration:  250 / 2500 [ 10%]  (Warmup) #> Chain 1: Iteration:  500 / 2500 [ 20%]  (Warmup) #> Chain 1: Iteration:  750 / 2500 [ 30%]  (Warmup) #> Chain 1: Iteration: 1000 / 2500 [ 40%]  (Warmup) #> Chain 1: Iteration: 1001 / 2500 [ 40%]  (Sampling) #> Chain 1: Iteration: 1250 / 2500 [ 50%]  (Sampling) #> Chain 1: Iteration: 1500 / 2500 [ 60%]  (Sampling) #> Chain 1: Iteration: 1750 / 2500 [ 70%]  (Sampling) #> Chain 1: Iteration: 2000 / 2500 [ 80%]  (Sampling) #> Chain 1: Iteration: 2250 / 2500 [ 90%]  (Sampling) #> Chain 1: Iteration: 2500 / 2500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.468873 seconds (Warm-up) #> Chain 1:                0.343155 seconds (Sampling) #> Chain 1:                0.812028 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL '006ab23433c79b9b7b0940468909174a' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.5e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2500 [  0%]  (Warmup) #> Chain 2: Iteration:  250 / 2500 [ 10%]  (Warmup) #> Chain 2: Iteration:  500 / 2500 [ 20%]  (Warmup) #> Chain 2: Iteration:  750 / 2500 [ 30%]  (Warmup) #> Chain 2: Iteration: 1000 / 2500 [ 40%]  (Warmup) #> Chain 2: Iteration: 1001 / 2500 [ 40%]  (Sampling) #> Chain 2: Iteration: 1250 / 2500 [ 50%]  (Sampling) #> Chain 2: Iteration: 1500 / 2500 [ 60%]  (Sampling) #> Chain 2: Iteration: 1750 / 2500 [ 70%]  (Sampling) #> Chain 2: Iteration: 2000 / 2500 [ 80%]  (Sampling) #> Chain 2: Iteration: 2250 / 2500 [ 90%]  (Sampling) #> Chain 2: Iteration: 2500 / 2500 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.440366 seconds (Warm-up) #> Chain 2:                0.308421 seconds (Sampling) #> Chain 2:                0.748787 seconds (Total) #> Chain 2: BayesCal"},{"path":"https://tripati-lab.github.io/bayclumpr/articles/bayclumpr.html","id":"reconstructing-temperatures-in-bayclumpr","dir":"Articles","previous_headings":"","what":"Reconstructing temperatures in bayclumpr","title":"bayclumpr","text":"bayclumpr implements two functions perform temperature reconstructions frequentist (rec.clumped) Bayesian frameworks (rec.bayesian). Let’s review functions work generating synthetic dataset two samples. calibration step, bayclumpr expects uncertainty (D47error) expressed terms standard deviation. Note recData object generated includes smallest number columns needed perform reconstructions bayclumpr. point, need either specify distribution parameter estimates calibration step. instance, let’s assume interested reconstructing temperatures recData OLS model. First, run calibration analyses: point, can use rec.clumped reconstruct temperatures based reconstruction dataset (recData argument) observed calibration object (obCal argument): resulting object includes information template reconstruction dataset also information reconstructed temperature associated uncertainty (1 SD). Let’s now perform reconstructions Bayesian framework. , need parameter estimates derived calibration step (see BayesCal created ). perform reconstructions single Bayesian models equivalent OLS fit Bayesian framework (BayesCal$BLM1_fit_NoErrors). associated reconstructions Bayesian model shown :","code":"recData <- data.frame(Sample = paste(\"Sample\", 1:9),                        D47 = rep(c(0.6, 0.7, 0.8), 3),                        D47error = c(rep(0.005,3), rep(0.01,3), rep(0.02,3)),                       N = rep(2, 9),                       Material = rep(1, 9)) paramdist <- cal.ols(data = ds, replicates = 10) rec.clumped(recData = recData, obCal = paramdist) #>     Sample D47 D47error  meanTemp    error #> 1 Sample 1 0.6    0.005  59.79108 2.509437 #> 2 Sample 2 0.7    0.005  18.30648 1.687880 #> 3 Sample 3 0.8    0.005 -10.74432 1.233827 #> 4 Sample 4 0.6    0.010  59.79108 4.962974 #> 5 Sample 5 0.7    0.010  18.30648 3.346772 #> 6 Sample 6 0.8    0.010 -10.74432 2.450411 #> 7 Sample 7 0.6    0.020  59.79108 9.710425 #> 8 Sample 8 0.7    0.020  18.30648 6.580837 #> 9 Sample 9 0.8    0.020 -10.74432 4.833432 PredsBay <- rec.bayesian(calModel = BayesCal$BLM1_fit_NoErrors, recData = recData, iter = 1000, postcalsamples = 100, MC = FALSE) #>  #> SAMPLING FOR MODEL 'd9c8b77ff79c7cb5c71ff874a6d29fd0' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 7.6e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.635986 seconds (Warm-up) #> Chain 1:                0.531588 seconds (Sampling) #> Chain 1:                1.16757 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'd9c8b77ff79c7cb5c71ff874a6d29fd0' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 5.4e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.54 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.627802 seconds (Warm-up) #> Chain 2:                0.545149 seconds (Sampling) #> Chain 2:                1.17295 seconds (Total) #> Chain 2: PredsBay #>     Sample D47 D47error  meanTemp     error #> 1 Sample 1 0.6    0.005  60.21022 0.7226459 #> 2 Sample 2 0.7    0.005  18.70703 0.4668382 #> 3 Sample 3 0.8    0.005 -10.36620 0.3430503 #> 4 Sample 4 0.6    0.010  60.19585 0.6755755 #> 5 Sample 5 0.7    0.010  18.69667 0.5170229 #> 6 Sample 6 0.8    0.010 -10.36899 0.3411882 #> 7 Sample 7 0.6    0.020  60.19985 0.7097546 #> 8 Sample 8 0.7    0.020  18.71255 0.4440080 #> 9 Sample 9 0.8    0.020 -10.37417 0.3605431"},{"path":"https://tripati-lab.github.io/bayclumpr/articles/bayclumpr.html","id":"outlook","dir":"Articles","previous_headings":"","what":"Outlook","title":"bayclumpr","text":"reviewed fundamental aspects using bayclumpr. advances analyses involving alternative priors Bayesian models option.","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Cristian Roman Palacios. Author, maintainer. Hannah M. Carroll. Author. Aradhna Tripati. Author.","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Roman Palacios C, Carroll H, Tripati (2023). bayclumpr: Bayesian Analysis Clumped Isotope Datasets. https://bayclump.tripatilab.epss.ucla.edu/, https://tripati-lab.github.io/bayclumpr/.","code":"@Manual{,   title = {bayclumpr: Bayesian Analysis of Clumped Isotope Datasets},   author = {Cristian {Roman Palacios} and Hannah M. Carroll and Aradhna Tripati},   year = {2023},   note = {https://bayclump.tripatilab.epss.ucla.edu/, https://tripati-lab.github.io/bayclumpr/}, }"},{"path":[]},{"path":[]},{"path":"https://tripati-lab.github.io/bayclumpr/index.html","id":"what-is-bayclumpr","dir":"","previous_headings":"","what":"What is bayclumpr?","title":"Bayesian Analysis of Clumped Isotope Datasets","text":"support use Bayesian models analytical framework developed Román-Palacios et al. (2022) clumped isotope calibration temperature reconstructions, facilitate comparisons Bayesian classical models, present self-contained R package associated Shiny Dashboard application, bayclumpr BayClump, respectively. bayclumpr (BayClump) fits frequentist Bayesian linear regressions calibration datasets performs temperature reconstructions frameworks. can find details use bayclumpr website.","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/index.html","id":"what-is-bayclump","dir":"","previous_headings":"","what":"What is BayClump?","title":"Bayesian Analysis of Clumped Isotope Datasets","text":"BayClump associated Shiny Dashboard application associated bayclumpr R package. functions implemented BayClump sourced bayclumpr. eveloped BayClump allow users less coding experience able access standarized resources calibrate derive reconstructions using clumped isotope datasets. can access BayClump directly .","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/index.html","id":"installing-bayclumpr","dir":"","previous_headings":"","what":"Installing bayclumpr","title":"Bayesian Analysis of Clumped Isotope Datasets","text":"latest version bayclumpr can installed directly GitHub repository using following lines code R","code":"library(devtools) install_github(\"Tripati-Lab/bayclumpr\")"},{"path":"https://tripati-lab.github.io/bayclumpr/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Bayesian Analysis of Clumped Isotope Datasets","text":"Please see contributing guide.","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/index.html","id":"contact","dir":"","previous_headings":"","what":"Contact","title":"Bayesian Analysis of Clumped Isotope Datasets","text":"Please see package DESCRIPTION package authors.","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.bayesian.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian regressions to calibrate the clumped isotopes paleothermometer using\nstan. — cal.bayesian","title":"Bayesian regressions to calibrate the clumped isotopes paleothermometer using\nstan. — cal.bayesian","text":"Bayesian regressions calibrate clumped isotopes paleothermometer using stan.","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.bayesian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian regressions to calibrate the clumped isotopes paleothermometer using\nstan. — cal.bayesian","text":"","code":"cal.bayesian(   calibrationData,   numSavedSteps = 3000,   priors = \"Informative\",   MC = TRUE )"},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.bayesian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian regressions to calibrate the clumped isotopes paleothermometer using\nstan. — cal.bayesian","text":"calibrationData target calibration dataset. numSavedSteps Number MCMC iterations save. priors Either Informative, Weak, Uninformative slope intercept. MC Multicore (TRUE/FALSE)","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.ci.html","id":null,"dir":"Reference","previous_headings":"","what":"This function is used to generate CI estimates at given intervals. It is currently\nused for plotting in BayClump. — cal.ci","title":"This function is used to generate CI estimates at given intervals. It is currently\nused for plotting in BayClump. — cal.ci","text":"function used generate CI estimates given intervals. currently used plotting BayClump.","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.ci.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function is used to generate CI estimates at given intervals. It is currently\nused for plotting in BayClump. — cal.ci","text":"","code":"cal.ci(data, from, to, length.out = 100)"},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.ci.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function is used to generate CI estimates at given intervals. It is currently\nused for plotting in BayClump. — cal.ci","text":"data data.frame two columns named beta alpha. result bootstrapping posterior distribution given calibration set. lower limit x. upper limit x. length.number breaks.","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a synthetic dataset for clumped isotopes calibrations — cal.dataset","title":"Generate a synthetic dataset for clumped isotopes calibrations — cal.dataset","text":"Generate synthetic dataset clumped isotopes calibrations","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a synthetic dataset for clumped isotopes calibrations — cal.dataset","text":"","code":"cal.dataset(error = \"S1\", nobs = 1000)"},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a synthetic dataset for clumped isotopes calibrations — cal.dataset","text":"error Error scenario: low (S1), Intermediate (S2), High (S3) nobs Number observations simulated dataset","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.deming.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Deming regression models on a given calibration dataset — cal.deming","title":"Fit Deming regression models on a given calibration dataset — cal.deming","text":"Fit Deming regression models given calibration dataset","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.deming.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Deming regression models on a given calibration dataset — cal.deming","text":"","code":"cal.deming(data, replicates, samples = NULL)"},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.deming.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Deming regression models on a given calibration dataset — cal.deming","text":"data calibration dataset replicates Number bootstrap replicates samples Number samples per bootstrap replicate","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.ols.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit OLS regression models on a given calibration dataset — cal.ols","title":"Fit OLS regression models on a given calibration dataset — cal.ols","text":"Fit OLS regression models given calibration dataset","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.ols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit OLS regression models on a given calibration dataset — cal.ols","text":"","code":"cal.ols(data, replicates, samples = NULL)"},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.ols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit OLS regression models on a given calibration dataset — cal.ols","text":"data calibration dataset replicates Number bootstrap replicates samples Number samples per bootstrap replicate","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a dataset reflecting the priors used to run the analyses — cal.prior","title":"Generate a dataset reflecting the priors used to run the analyses — cal.prior","text":"Generate dataset reflecting priors used run analyses","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a dataset reflecting the priors used to run the analyses — cal.prior","text":"","code":"cal.prior(prior, n = 1000)"},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a dataset reflecting the priors used to run the analyses — cal.prior","text":"prior Informative n number observations simulate","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.wols.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit weighted OLS regression models on a given calibration dataset — cal.wols","title":"Fit weighted OLS regression models on a given calibration dataset — cal.wols","text":"Fit weighted OLS regression models given calibration dataset","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.wols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit weighted OLS regression models on a given calibration dataset — cal.wols","text":"","code":"cal.wols(data, replicates, samples = NULL)"},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.wols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit weighted OLS regression models on a given calibration dataset — cal.wols","text":"data calibration dataset replicates Number bootstrap replicates samples Number samples per bootstrap replicate","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.york.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit York regression models on a given calibration dataset — cal.york","title":"Fit York regression models on a given calibration dataset — cal.york","text":"Fit York regression models given calibration dataset","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.york.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit York regression models on a given calibration dataset — cal.york","text":"","code":"cal.york(data, replicates, samples = NULL)"},{"path":"https://tripati-lab.github.io/bayclumpr/reference/cal.york.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit York regression models on a given calibration dataset — cal.york","text":"data calibration dataset replicates Number bootstrap replicates samples Number samples per bootstrap replicate","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/rec.bayesian.html","id":null,"dir":"Reference","previous_headings":"","what":"This function generate temperature predictions (in 10^6/T2) based on a\ncalibration dataset and target D47. Note that this approach additionally\naccounts for measured error in the target D47. This approach is congruent\nwith the one used in McClelland et al. (2022). — rec.bayesian","title":"This function generate temperature predictions (in 10^6/T2) based on a\ncalibration dataset and target D47. Note that this approach additionally\naccounts for measured error in the target D47. This approach is congruent\nwith the one used in McClelland et al. (2022). — rec.bayesian","text":"function generate temperature predictions (10^6/T2) based calibration dataset target D47. Note approach additionally accounts measured error target D47. approach congruent one used McClelland et al. (2022).","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/rec.bayesian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function generate temperature predictions (in 10^6/T2) based on a\ncalibration dataset and target D47. Note that this approach additionally\naccounts for measured error in the target D47. This approach is congruent\nwith the one used in McClelland et al. (2022). — rec.bayesian","text":"","code":"rec.bayesian(   calModel,   recData,   iter = 1000,   mixed = FALSE,   postcalsamples = NULL,   MC = TRUE )"},{"path":"https://tripati-lab.github.io/bayclumpr/reference/rec.bayesian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function generate temperature predictions (in 10^6/T2) based on a\ncalibration dataset and target D47. Note that this approach additionally\naccounts for measured error in the target D47. This approach is congruent\nwith the one used in McClelland et al. (2022). — rec.bayesian","text":"calModel stan model analyzed. recData reconstruction dataset. iter Number replicates retain. mixed whether model calModel mixed . postcalsamples Number posterior samples analyze calibration step. MC Multicore (TRUE/FALSE)","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/rec.clumped.html","id":null,"dir":"Reference","previous_headings":"","what":"This function performs temp reconstruction (10^6/T^2 with T in K) for\nmultiple replicates of the same target. — rec.clumped","title":"This function performs temp reconstruction (10^6/T^2 with T in K) for\nmultiple replicates of the same target. — rec.clumped","text":"function performs temp reconstruction (10^6/T^2 T K) multiple replicates target.","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/rec.clumped.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function performs temp reconstruction (10^6/T^2 with T in K) for\nmultiple replicates of the same target. — rec.clumped","text":"","code":"rec.clumped(recData, obCal)"},{"path":"https://tripati-lab.github.io/bayclumpr/reference/rec.clumped.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function performs temp reconstruction (10^6/T^2 with T in K) for\nmultiple replicates of the same target. — rec.clumped","text":"recData Reconstruction dataset obCal data.frame summarizing distribution slopes intercepts","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/rec.prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a dataset reflecting the priors used to run the analyses — rec.prior","title":"Generate a dataset reflecting the priors used to run the analyses — rec.prior","text":"Generate dataset reflecting priors used run analyses","code":""},{"path":"https://tripati-lab.github.io/bayclumpr/reference/rec.prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a dataset reflecting the priors used to run the analyses — rec.prior","text":"","code":"rec.prior(prior, n = 1000)"},{"path":"https://tripati-lab.github.io/bayclumpr/reference/rec.prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a dataset reflecting the priors used to run the analyses — rec.prior","text":"prior Informative n number observations simulate","code":""}]
